---
title: "p8105_hw2_xc2784"
output: github_document
date: "2025-10-01"
---

```{r}
library(tidyverse)
```


## Problem 1
First, clean the data in pols-month.csv
```{r}
pols_df = read_csv(file = "./fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year","month","day"), sep = "-") %>% 
  mutate(year = as.integer(year), 
         month = month.abb[as.integer(month)],
         president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )) %>%
  select(-day,-prez_gop,-prez_dem)
```
Second, clean the data in snp.csv 
```{r}
snp_df = read_csv(file = "./fivethirtyeight_datasets/snp.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month","day","year"), sep = "/") %>% 
  mutate(month = month.abb[as.integer(month)],
         year = as.integer(year),  
         year = ifelse(year < 30, year + 2000, year + 1900)) %>% 
  select(year, month, everything())

```

Third, tidy the unemployment data
```{r}
unemployment_df = read_csv(file = "./fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) %>% 
  pivot_longer(Jan:Dec,names_to = "month",values_to = "unemployment") %>%
  janitor::clean_names() 
```

Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r}
result_df = left_join(pols_df,snp_df, by = c("year","month")) %>% 
  left_join(unemployment_df, by = c("year","month"))
colnames(result_df)
```
pols contains information about the number of national politicians who are democratic or republican from 1947 to 2015.
snp contains information about the closing values of the S&P stock index on the associated date, from 1950 to 2015.
unemployment contains information about percentage of unemployment in the month, from 1948 to 2015.
The final resulting dataset has 822 entries and 12 total columns, with year from 1947 to 2015. Key variable names:  "year"         "month"        "gov_gop"      "sen_gop"      "rep_gop"     "gov_dem"      "sen_dem"      "rep_dem"      "president"    "day"  "close"        "unemployment"

## Problem 2

```{r}
library(readxl)
```
Read and clean the 3 Trash Wheel sheet
```{r}
mr_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",
                   range = "A2:N709",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>%
  mutate(year = as.integer(year),sports_balls = as.integer(round(sports_balls, 0)),trash_wheel="Mr. Trash Wheel")
```
Read and clean the Professor Trash Wheel
```{r}
professor_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",
                   range = "A2:M134",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.integer(year), trash_wheel="Professor Trash Wheel")
```
Read and clean the Gwynns Falls Trash Wheel
```{r}
gwynns_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Gwynns Falls Trash Wheel",
                   range = "A2:L351",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.integer(year), trash_wheel = "Gwynns Falls Trash Wheel")
```
Bind 3 datasets
```{r}
ts_final = 
  bind_rows(mr_df, professor_df, gwynns_df) %>% 
  janitor::clean_names() %>% 
  select(trash_wheel, everything())
colnames(ts_final)
```
The Trash Wheel dataset provides a record of the waste collected by different trash wheels in Baltimore. 
The resulting dataset has 1,188 observations and 15 total columns.The key variables include  "trash_wheel"        "dumpster"           "month"              "year"               "date"               "weight_tons"        "volume_cubic_yards" "plastic_bottles"    "polystyrene"        "cigarette_butts"    "glass_bottles"      "plastic_bags"       "wrappers"           "sports_balls"       "homes_powered" .

For the available data, Professor Trash Wheel has collected a total of `r sum(professor_df$weight_tons, na.rm = TRUE)` tons of trash. 
Gwynnda collected `r sum(gwynns_df$cigarette_butts[gwynns_df$year == 2022 & gwynns_df$month == "June"], na.rm = TRUE)` cigarette butts in June 2022.

## Problem 3
Import and clean zori data
```{r}
zori_df = read_csv(file = "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  rename(zip_code = region_name ) %>% 
  select(-state_name, -county_name) %>% 
  pivot_longer(cols = starts_with("x"),
               names_to = "date",
               values_to = "zori") %>% 
  mutate(date = str_remove(date, "^x"), 
         date = as.Date(date, format = "%Y_%m_%d"))  
```

Import and clean zipcode data
```{r}
zip_df = read_csv(file = "./zillow_data/Zip Codes.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y"))%>% 
  rename (borough = county)%>%
  mutate( borough = recode (borough,
                     "New York" = "Manhattan",
                     "Kings" = "Brooklyn",
                     "Richmond" = "Staten Island")
  )
```

Join two datasets and reorder
```{r}
tidy_df = left_join(zip_df,zori_df, by = "zip_code",relationship = "many-to-many") %>% 
  select(region_id, zip_code,state,city,borough,neighborhood,date,zori,everything()) %>% 
  arrange(zip_code)
```

The resulting tidy dataset has 17,687 observations and 15 columns. It includes `r n_distinct(tidy_df$zip_code)` unique ZIP codes and 
`r n_distinct(tidy_df$neighborhood)` unique neighborhoods.

```{r}
missing_zip <- setdiff(zip_df$zip_code, zori_df$zip_code)
n_distinct(missing_zip)
```

There are `r n_distinct(setdiff(zip_df$zip_code, zori_df$zip_code))` ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset. These missing ZIP codes are often areas with limited or no residential housing, such as industrial zones or areas dominated by openspace. For example, 10464 is located in southeast New York and is Primarily City Island, resulting in very few housing. Also, some newly assigned zipcodes may not have sufficient rental listings for Zillow to provide reliable estimates, thus being excluded from dataset.

```{r}
drop <- tidy_df %>%
  filter(date %in% c("2020-01-31", "2021-01-31")) %>%
  select(zip_code, borough, neighborhood, date, zori) %>%
  pivot_wider(names_from = date, values_from = zori) %>%
  rename ( zori_2020 = "2020-01-31",zori_2021 = "2021-01-31") %>% 
  mutate(diff = zori_2021- zori_2020) %>% 
  arrange(diff) %>% 
  head(10)
```

The table shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021. All 10 of them comes from Manhattan. The data shows that ZIP codes in Manhattan experienced the largest rental price drop from January 2020 to 2021, particularly in areas such as Lower Manhattan.




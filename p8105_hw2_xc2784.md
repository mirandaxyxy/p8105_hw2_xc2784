p8105_hw2_xc2784
================
2025-10-01

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

## Problem 1

First, import then clean the data in pols-month.csv

``` r
pols_df = read_csv(file = "./fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year","month","day"), sep = "-") %>% 
  mutate(year = as.integer(year), 
         month = month.abb[as.integer(month)],
         president = case_when(
      prez_gop == 1 ~ "gop",
      prez_dem == 1 ~ "dem"
    )) %>%
  select(-day,-prez_gop,-prez_dem)
```

Second, import then clean the data in snp.csv

``` r
snp_df = read_csv(file = "./fivethirtyeight_datasets/snp.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(date = mdy(date),
         year = year(date), 
         month = month(date,label = TRUE,abbr=TRUE),
         day = day(date))  %>% 
  select(year, month, everything())
```

Third, import then tidy the unemployment data

``` r
unemployment_df = read_csv(file = "./fivethirtyeight_datasets/unemployment.csv", show_col_types = FALSE) %>% 
  pivot_longer(Jan:Dec,names_to = "month",values_to = "unemployment") %>%
  janitor::clean_names() 
```

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
result_df = left_join(pols_df,snp_df, by = c("year","month")) %>% 
  left_join(unemployment_df, by = c("year","month"))
colnames(result_df)
```

    ##  [1] "year"         "month"        "gov_gop"      "sen_gop"      "rep_gop"     
    ##  [6] "gov_dem"      "sen_dem"      "rep_dem"      "president"    "date"        
    ## [11] "close"        "day"          "unemployment"

pols contains information about the number of national politicians who
are democratic or republican in each month, from 1947 to 2015. snp
contains information about the closing values of the S&P stock index on
the associated date, from 1950 to 2015. unemployment contains
information about percentage of unemployment in the month, from 1948 to
2015.

The final resulting dataset has 822 entries and 12 total columns, with
year from 1947 to 2015. Key variable names: “year” “month” “president”
“close” “unemployment”.

## Problem 2

``` r
library(readxl)
```

Read and clean the Mr.Trash Wheel sheet

``` r
mr_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Mr. Trash Wheel",
                   range = "A2:N709",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>%
  mutate(year = as.integer(year),sports_balls = as.integer(round(sports_balls, 0)),trash_wheel = "Mr. Trash Wheel")
```

Read and clean the Professor Trash Wheel

``` r
professor_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Professor Trash Wheel",
                   range = "A2:M134",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.integer(year), trash_wheel="Professor Trash Wheel")
```

Read and clean the Gwynns Falls Trash Wheel

``` r
gwynns_df = read_excel("./202509 Trash Wheel Collection Data.xlsx",sheet = "Gwynns Falls Trash Wheel",
                   range = "A2:L351",col_names = TRUE) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(year = as.integer(year), trash_wheel = "Gwynns Falls Trash Wheel")
```

Bind 3 datasets

``` r
ts_final = 
  bind_rows(mr_df, professor_df, gwynns_df) %>% 
  janitor::clean_names() %>% 
  select(trash_wheel, everything())
colnames(ts_final)
```

    ##  [1] "trash_wheel"        "dumpster"           "month"             
    ##  [4] "year"               "date"               "weight_tons"       
    ##  [7] "volume_cubic_yards" "plastic_bottles"    "polystyrene"       
    ## [10] "cigarette_butts"    "glass_bottles"      "plastic_bags"      
    ## [13] "wrappers"           "sports_balls"       "homes_powered"

The Trash Wheel dataset provides a record of the waste collected by
different trash wheels in Baltimore. The resulting dataset has 1,188
observations and 15 total columns.The key variables include
“trash_wheel” “dumpster” “month” “year” “date” “weight_tons”
“volume_cubic_yards” “plastic_bottles” “polystyrene” “cigarette_butts”
“glass_bottles” “plastic_bags” “wrappers” “sports_balls” “homes_powered”
.

For the available data, Professor Trash Wheel has collected a total of
282.26 tons of trash. Gwynnda collected 1.812^{4} cigarette butts in
June 2022.

## Problem 3

Import and clean zori data

``` r
zori_df = read_csv(file = "./zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  rename(zip_code = region_name ) %>% 
  select(-state_name, -county_name) %>% 
  pivot_longer(cols = starts_with("x"),
               names_to = "date",
               values_to = "zori") %>% 
  mutate(date = str_remove(date, "^x"), 
         date = as.Date(date, format = "%Y_%m_%d"))  
```

Import and clean zip code data

``` r
zip_df = read_csv(file = "./zillow_data/Zip Codes.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(file_date = as.Date(file_date, format = "%m/%d/%y")) %>% 
  rename(borough = county) %>%
  mutate(borough = recode(borough,
                     "New York" = "Manhattan",
                     "Kings" = "Brooklyn",
                     "Richmond" = "Staten Island")) 
```

Join two datasets and reorder

``` r
zip_df_unique = zip_df %>% 
  distinct(zip_code, .keep_all = TRUE)

tidy_df = left_join(zori_df,zip_df_unique, by = "zip_code") %>% distinct() %>%  
  select(region_id, zip_code,state,city,borough,neighborhood,date,zori,everything()) %>% 
  arrange(zip_code)

tidy_df
```

    ## # A tibble: 17,284 × 15
    ##    region_id zip_code state city     borough   neighborhood     date        zori
    ##        <dbl>    <dbl> <chr> <chr>    <chr>     <chr>            <date>     <dbl>
    ##  1     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-01-31 3855.
    ##  2     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-02-28 3892.
    ##  3     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-03-31 3898.
    ##  4     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-04-30 3970.
    ##  5     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-05-31 4033.
    ##  6     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-06-30 4071.
    ##  7     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-07-31 4067.
    ##  8     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-08-31 4070.
    ##  9     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-09-30 4040.
    ## 10     61615    10001 NY    New York Manhattan Chelsea and Cli… 2015-10-31 4023.
    ## # ℹ 17,274 more rows
    ## # ℹ 7 more variables: size_rank <dbl>, region_type <chr>, metro <chr>,
    ## #   state_fips <dbl>, county_code <chr>, county_fips <dbl>, file_date <date>

The resulting tidy dataset has 17,284 observations and 15 columns. It
includes 149 unique ZIP codes and 43 unique neighborhoods.

``` r
missing_zip <- setdiff(zip_df$zip_code, zori_df$zip_code)
n_distinct(missing_zip)
```

    ## [1] 171

There are 171 ZIP codes appear in the ZIP code dataset but not in the
Zillow Rental Price dataset. These missing ZIP codes are often areas
with limited or no residential housing, such as industrial zones or
areas dominated by openspace. For example, 10464 is located in southeast
New York and is Primarily City Island, resulting in very few housing.
Also, some newly assigned zipcodes may not have sufficient rental
listings for Zillow to provide reliable estimates, thus being excluded
from dataset.

``` r
drop <- tidy_df %>%
  filter(date %in% c("2020-01-31", "2021-01-31")) %>%
  select(zip_code, borough, neighborhood, date, zori) %>%
  pivot_wider(names_from = date, values_from = zori) %>%
  rename ( zori_2020 = "2020-01-31",zori_2021 = "2021-01-31") %>% 
  mutate(diff = zori_2021- zori_2020) %>% 
  arrange(diff) %>% 
  head(10)

drop
```

    ## # A tibble: 10 × 6
    ##    zip_code borough   neighborhood                  zori_2020 zori_2021  diff
    ##       <dbl> <chr>     <chr>                             <dbl>     <dbl> <dbl>
    ##  1    10007 Manhattan Lower Manhattan                   6334.     5422. -913.
    ##  2    10069 Manhattan <NA>                              4623.     3875. -748.
    ##  3    10009 Manhattan Lower East Side                   3406.     2692. -714.
    ##  4    10016 Manhattan Gramercy Park and Murray Hill     3731.     3019. -712.
    ##  5    10001 Manhattan Chelsea and Clinton               4108.     3398. -710.
    ##  6    10002 Manhattan Lower East Side                   3645.     2935. -710.
    ##  7    10004 Manhattan Lower Manhattan                   3150.     2444. -706.
    ##  8    10038 Manhattan Lower Manhattan                   3573.     2876. -698.
    ##  9    10012 Manhattan Greenwich Village and Soho        3629.     2942. -686.
    ## 10    10010 Manhattan Gramercy Park and Murray Hill     3697.     3012. -685.

The table shows the 10 ZIP codes (along with the borough and
neighborhood) with largest drop in price from January 2020 to 2021. All
10 of them comes from Manhattan. The data shows that ZIP codes in
Manhattan experienced the largest rental price drop from January 2020 to
2021, particularly in areas such as Lower Manhattan.
